{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 1: Configuração do Ambiente no Google Colab**\n",
        "Primeiro, preparamos o ambiente no Colab, habilitando a GPU e conectando ao seu Google Drive para acessar os dados."
      ],
      "metadata": {
        "id": "vzxdmgYYqkxW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44b9653c",
        "outputId": "4cb24728-5b0c-4a59-e60f-44d643cdab6a"
      },
      "source": [
        "# Mount Google Drive to access our dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 2: Preparação do Dataset**<BR>\n",
        "Agora vamos carregar e pré-processar suas imagens. As transformações definidas são padrão para modelos pré-treinados no ImageNet."
      ],
      "metadata": {
        "id": "-P7YP-xGqp66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 1. Define the image transformations\n",
        "# Images will be resized, cropped, converted to tensors, and normalized.\n",
        "# Normalization uses the standard mean and std dev from ImageNet models.\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# 2. Set the path to your train and validation folders on Google Drive\n",
        "# ATTENTION: Adjust this path to where you saved your dataset!\n",
        "train_path = '/content/drive/MyDrive/DEV/dataset_pizza_burger/training'\n",
        "validation_path = '/content/drive/MyDrive/DEV/dataset_pizza_burger/validation'\n",
        "\n",
        "# 3. Load the datasets using ImageFolder\n",
        "train_dataset = datasets.ImageFolder(train_path, transform=transform)\n",
        "validation_dataset = datasets.ImageFolder(validation_path, transform=transform)\n",
        "\n",
        "# 4. Create the DataLoaders\n",
        "# They are responsible for loading the data in batches.\n",
        "trainloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valloader = DataLoader(validation_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Check the classes that were found (should be ['burger', 'pizza'])\n",
        "print(\"Classes found:\", train_dataset.classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc39tQVQpvQ9",
        "outputId": "94ea72d2-d517-4f11-a367-bf1234031564"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes found: ['burger', 'pizza']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 3: Escolha e Carregamento do Modelo Pré-treinado**\n",
        "\n",
        "Vamos usar a ResNet18, um modelo famoso e eficiente que já foi treinado no dataset ImageNet."
      ],
      "metadata": {
        "id": "HK-KqdojqzBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pretrained ResNet18 model\n",
        "model = models.resnet18(pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNjpPMzpqeU9",
        "outputId": "8eb42238-9fc7-46f4-9303-7f3254fa9957"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 4: Adaptação do Modelo para o Nosso Problema**\n",
        "\n",
        "Esta é a etapa central do Transfer Learning. Primeiro, \"congelamos\" as camadas que já foram treinadas para não perdermos o conhecimento adquirido. Depois, substituímos a camada de classificação final para que ela se ajuste ao nosso problema de 2 classes."
      ],
      "metadata": {
        "id": "7M-PCR4yq6kj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "# 1. Freeze the parameters of the pretrained model\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 2. Replace the final layer (the classifier)\n",
        "# The original classifier of ResNet18 is named 'fc' (fully connected).\n",
        "# It has 512 input features and 1000 output features (for ImageNet).\n",
        "# We will replace it with a new one with 512 inputs and 2 outputs for our classes.\n",
        "n_inputs = model.fc.in_features\n",
        "model.fc = nn.Linear(n_inputs, 2) # 2 classes: pizza and burger"
      ],
      "metadata": {
        "id": "wKb4xuvPq90U"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 5: Definição do Otimizador e da Função de Perda**\n",
        "\n",
        "Configuramos as ferramentas para o novo treinamento. É importante notar que passamos para o otimizador apenas os parâmetros da nova camada que criamos, pois são os únicos que precisam ser treinados."
      ],
      "metadata": {
        "id": "QI59gZh0rL_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "\n",
        "# Loss Function - CrossEntropyLoss is standard for classification\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer - Adam is a robust choice\n",
        "# IMPORTANT: We only pass the parameters of the new final layer, as these are the only ones that need to be trained.\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "# Move the model to the GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaVBheE9rQON",
        "outputId": "31e46f6b-3a23-42ab-e51c-cc7c6f1bd822"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 6: Treinamento e Validação do Modelo**\n",
        "\n",
        "Agora executamos o loop de treinamento. Este código já inclui a fase de validação para monitorar o desempenho do modelo em dados que ele não viu durante o treino."
      ],
      "metadata": {
        "id": "_YeJt7thrhza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def train_and_validate(model, trainloader, valloader, criterion, optimizer, device, epochs=5): # <- 5 epochs\n",
        "    \"\"\"\n",
        "    Function to train and validate a PyTorch model.\n",
        "    \"\"\"\n",
        "    print(\"Starting training...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # --- Training Phase ---\n",
        "        model.train()  # Set model to training mode\n",
        "        train_loss = 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(images)\n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # --- Validation Phase ---\n",
        "        model.eval()  # Set model to evaluation mode\n",
        "        validation_loss = 0.0\n",
        "        accuracy = 0\n",
        "        with torch.no_grad(): # Disable gradient calculation for validation\n",
        "            for images, labels in valloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                output = model(images)\n",
        "                validation_loss += criterion(output, labels).item()\n",
        "\n",
        "                # Calculate accuracy\n",
        "                ps = torch.exp(output)\n",
        "                top_p, top_class = ps.topk(1, dim=1)\n",
        "                equals = top_class == labels.view(*top_class.shape)\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "              f\"Train Loss: {train_loss/len(trainloader):.4f} | \"\n",
        "              f\"Validation Loss: {validation_loss/len(valloader):.4f} | \"\n",
        "              f\"Validation Accuracy: {accuracy/len(valloader)*100:.2f}%\")\n",
        "\n",
        "    total_time = (time.time() - start_time) / 60\n",
        "    print(f\"\\nTraining finished in {total_time:.2f} minutes.\")\n",
        "\n",
        "# Start the training!\n",
        "history = train_and_validate(model, trainloader, valloader, criterion, optimizer, device, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjAweTKGrqxw",
        "outputId": "e6a1fa2a-c886-4cf6-b979-b001b9c9bcad"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 | Train Loss: 0.8169 | Validation Loss: 0.6813 | Validation Accuracy: 60.59%\n",
            "Epoch 2/5 | Train Loss: 0.5517 | Validation Loss: 0.5328 | Validation Accuracy: 74.83%\n",
            "Epoch 3/5 | Train Loss: 0.4047 | Validation Loss: 0.3290 | Validation Accuracy: 88.19%\n",
            "Epoch 4/5 | Train Loss: 0.3163 | Validation Loss: 0.2929 | Validation Accuracy: 95.31%\n",
            "Epoch 5/5 | Train Loss: 0.2542 | Validation Loss: 0.2575 | Validation Accuracy: 95.31%\n",
            "\n",
            "Training finished in 2.17 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**O que observar na saída acima:**\n",
        "\n",
        "`Train Loss` (Perda de Treino): Mede o erro do modelo nos dados de treino. O esperado é que este número diminua a cada época, mostrando que o modelo está aprendendo.\n",
        "\n",
        "`Validation Loss` (Perda de Validação): Mede o erro nos dados que o modelo nunca viu (validação). Este é o indicador mais importante! O esperado é que ele também diminua. Se ele começar a subir enquanto a `Train Loss` continua caindo, é um sinal de overfitting.\n",
        "\n",
        "`Validation Accuracy` (Acurácia de Validação): A porcentagem de acertos nos dados de validação. O esperado é que este número aumente, chegando o mais perto possível de 100%.\n",
        "\n",
        "Após o término de todas as épocas, a última linha a ser impressa será o tempo total do processo."
      ],
      "metadata": {
        "id": "RdL6yLbRthJu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# O \"Produto\" Final: O Modelo Treinado\n",
        "Este é o resultado mais importante do projeto. Ao final do processo, a variável `model` não é mais um modelo genérico; ela agora contém os pesos ajustados e o conhecimento específico para diferenciar pizzas e hambúrgueres.\n",
        "\n",
        "Você pode usar este modelo treinado para fazer previsões em imagens novas que ele nunca viu antes. Por exemplo, você poderia adicionar uma nova célula no Colab para testar uma imagem da internet:"
      ],
      "metadata": {
        "id": "pPAMTjkqt03W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 7: Função de Predição**\n",
        "\n",
        "Esta é a função para fazer previsões em novas imagens da internet"
      ],
      "metadata": {
        "id": "QzUi5tYqxBMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELL 7: Prediction Function (FINAL CORRECTED VERSION) ---\n",
        "\n",
        "from PIL import Image\n",
        "import requests\n",
        "import io\n",
        "import torch\n",
        "\n",
        "def predict_image(image_url):\n",
        "    \"\"\"\n",
        "    Function to load an image from a URL and predict its class.\n",
        "    This version includes a User-Agent header to avoid blocking issues.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Define a browser-like header\n",
        "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}\n",
        "\n",
        "        # Get the image data from the URL using the header\n",
        "        response = requests.get(image_url, headers=headers)\n",
        "\n",
        "        # Check if the request was successful\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Convert the byte data into a file-like object\n",
        "        image_bytes = io.BytesIO(response.content)\n",
        "\n",
        "        # Open the image\n",
        "        image = Image.open(image_bytes).convert('RGB')\n",
        "\n",
        "    except requests.exceptions.HTTPError as errh:\n",
        "        print(f\"Http Error: {errh}\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading image: {e}\")\n",
        "        return\n",
        "\n",
        "    # Apply the same transformations as the training set\n",
        "    transformed_image = transform(image).unsqueeze(0)\n",
        "\n",
        "    model.eval() # Set the model to evaluation mode\n",
        "    with torch.no_grad(): # Disable gradient calculation\n",
        "        output = model(transformed_image.to(device))\n",
        "        ps = torch.exp(output)\n",
        "        top_p, top_class = ps.topk(1, dim=1)\n",
        "        prediction_idx = top_class.item()\n",
        "\n",
        "    classes = train_dataset.classes\n",
        "    prediction = classes[prediction_idx]\n",
        "    probability = top_p.item() * 100\n",
        "\n",
        "    print(f\"Prediction: The image is a: {prediction}\")\n",
        "    print(f\"Probability: {probability:.2f}%\")"
      ],
      "metadata": {
        "id": "roMHF9uWw8Vu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 8: Testar o Modelo Treinado**\n",
        "\n",
        "Finalmente, vamos testar nosso modelo com algumas imagens que ele nunca viu antes!"
      ],
      "metadata": {
        "id": "8ANPawunxOEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELL 8: Test the Trained Model ---\n",
        "\n",
        "# Example 1: Hamburger\n",
        "hamburger_url = \"https://i.imgur.com/YLPiFZh.jpeg\"\n",
        "print(f\"Testing image from: {hamburger_url}\")\n",
        "predict_image(hamburger_url)\n",
        "\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Example 2: Pizza\n",
        "pizza_url = \"https://i.imgur.com/eeDDFhu.jpeg\"\n",
        "print(f\"Testing image from: {pizza_url}\")\n",
        "predict_image(pizza_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAI_UNFHxUNG",
        "outputId": "9f270aef-ad17-42eb-c544-7ad26f4acff4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing image from: https://i.imgur.com/YLPiFZh.jpeg\n",
            "Prediction: The image is a: burger\n",
            "Probability: 671.37%\n",
            "------------------------------\n",
            "Testing image from: https://i.imgur.com/eeDDFhu.jpeg\n",
            "Prediction: The image is a: pizza\n",
            "Probability: 671.93%\n"
          ]
        }
      ]
    }
  ]
}